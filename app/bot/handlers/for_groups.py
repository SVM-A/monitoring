# bot/handlers/for_groups.py
import hashlib
import re
import html
import unicodedata
from datetime import datetime, timezone

from aiogram import Router, F, Bot
from aiogram.types import Message
from aiogram.exceptions import TelegramBadRequest
from sqlalchemy import select, text
from sqlalchemy.ext.asyncio.session import AsyncSession

from app.core.config import public_channel_comment_chat_id, elya_chat_id, public_channel_chat_id
from app.db.models.service_notifier import BanMessageText, norm_hash, normalize_message_text
from app.db.sessions import async_connect_db
from bot.utils.tools import normalize_message

groups_monitor_router = Router()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[ Ğ‘Ğ•Ğ›Ğ«Ğ™ Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ¡Ğ’ĞĞ˜Ğ¥ Ğ‘ĞĞ¢ĞĞ’ ]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ALLOWLIST_BOTS = {"beaheabot"}  # Ğ²ÑĞµ Ğ² Ğ½Ğ¸Ğ¶Ğ½ĞµĞ¼ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğµ

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[ Ğ Ğ•Ğ“Ğ£Ğ›Ğ¯Ğ ĞšĞ˜ Ğ”Ğ›Ğ¯ Ğ›ĞĞ’Ğ›Ğ˜ @handle / ÑÑÑ‹Ğ»Ğ¾Ğº ]â”€â”€â”€â”€â”€â”€â”€â”€
MENTION_RE = re.compile(r"(?<!\w)@(?P<u>[A-Za-z0-9_]{5,32})(?!\w)")

LINK_RE = re.compile(
    r"(?i)\b(?:https?://)?(?:t(?:elegram)?\.me|telegram\.me)/(?:s/)?(?P<u>[A-Za-z0-9_]{5,32})(?:\b|/|\?|#)"
)
TG_RESOLVE_RE = re.compile(r"(?i)\btg://resolve\?domain=(?P<u>[A-Za-z0-9_]{5,32})\b")

def _extract_usernames(text: str) -> set[str]:
    """Ğ”Ğ¾ÑÑ‚Ğ°Ñ‘Ğ¼ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° username Ğ¸Ğ· ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ ÑÑÑ‹Ğ»Ğ¾Ğº."""
    if not text:
        return set()
    usernames = set()
    for rx in (MENTION_RE, LINK_RE, TG_RESOLVE_RE):
        for m in rx.finditer(text):
            usernames.add(m.group("u"))
    return usernames

def _is_foreign_bot(username: str) -> bool:
    """Ğ¡Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ username Ğ±Ğ¾Ñ‚Ğ¾Ğ¼, ĞµÑĞ»Ğ¸ Ğ¾ĞºĞ°Ğ½Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° 'bot' (Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¾Ğ½ĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾) Ğ¸ Ğ½Ğµ Ğ² allowlist."""
    u = username.lower()
    return u.endswith("bot") and u not in ALLOWLIST_BOTS


# Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ ÑĞ¿Ğ°Ğ¼Ğ°

SPAM_MARKERS_RAW = [
    "Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ", "ĞºÑƒÑ€Ñ", "Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾ Ñ‚Ñ€ĞµĞ¹Ğ´Ğ¸Ğ½Ğ³Ñƒ", "Ñ‚Ñ€ĞµĞ¹Ğ´Ğ¸Ğ½Ğ³",
    "ĞºĞ¾Ğ¼Ñƒ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ", "Ğ¿ĞµÑ€ĞµÑˆĞ»Ñ", "Ğ·Ğ° ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾", "ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¿Ğ»Ğ°Ñ‚Ñƒ",
    "ÑĞ»Ğ¸Ğ²", "ÑĞ±Ñ€Ğ¾ÑĞ¸Ğ» Ğ¼Ğ½Ğµ", "Ğ´Ğ°Ğ²Ğ°Ğ¹ Ğ¿Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ñ", "Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ» Ğ½Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ†ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸"
]
SPAM_MARKERS = { normalize_message_text(x) for x in SPAM_MARKERS_RAW }

def keyword_score(norm: str) -> int:
    return sum(1 for k in SPAM_MARKERS if k in norm)

def looks_like_course_leak(norm: str) -> bool:
    # ĞĞ±Ñ‹Ñ‡Ğ½Ğ¾ 3â€“4 Ğ¼Ğ°Ñ€ĞºĞµÑ€Ğ° Ğ´Ğ°ÑÑ‚ Ñ…Ğ¾Ñ€Ğ¾ÑˆÑƒÑ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ.
    return keyword_score(norm) >= 3


def normalize_for_regex(raw: str) -> str:
    s = unicodedata.normalize("NFKD", raw)
    s = "".join(ch for ch in s if not unicodedata.combining(ch))
    s = s.lower()
    # Ğ·Ğ°Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ²ÑÑ‘, Ñ‡Ñ‚Ğ¾ Ğ½Ğµ Ğ±ÑƒĞºĞ²Ñ‹/Ñ†Ğ¸Ñ„Ñ€Ñ‹, Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ±ĞµĞ» Ğ¸ ÑÑ…Ğ»Ğ¾Ğ¿Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ñ‹
    s = re.sub(r"[^0-9a-zA-ZĞ°-ÑÑ‘Ğ-Ğ¯Ğ]+", " ", s)
    return re.sub(r"\s+", " ", s).strip()

REGEXES = [
    re.compile(r"(Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½|ĞºĞ°ĞºĞ¾Ğ¹[-\s]?Ğ½Ğ¸(Ğ±ÑƒĞ´ÑŒ|ĞºĞ°)|Ğ»ÑƒÑ‡ÑˆĞµ)\s+(ĞºÑƒÑ€Ñ|Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸[ĞµÑ])"),
    re.compile(r"(Ğ¿ĞµÑ€ĞµÑˆĞ»[ÑŒÑ]|Ğ´Ğ°Ğ¼\s+Ğ´Ğ¾ÑÑ‚ÑƒĞ¿|Ğ¿Ğ¾Ğ´ĞµĞ»ÑÑÑŒ)\b"),
    re.compile(r"\b(Ğ·Ğ°|Ñ€Ğ°Ğ´Ğ¸)\s+(ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾|Ğ´Ğ¾Ğ½Ğ°Ñ‚|ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¸Ñ‡ĞµÑĞº\w*\s+Ğ¿Ğ»Ğ°Ñ‚\w*)"),
    re.compile(r"(ĞºĞ¾Ğ¼Ñƒ|ĞµÑĞ»Ğ¸)\s+(Ğ½ÑƒĞ¶Ğ½Ğ¾|Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ğ¾)\s+(Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ|Ğ²\s+Ğ»Ñ|Ğ²\s+Ğ»Ğ¸Ñ‡Ğº\w*)"),
]

def rules_hit(raw: str) -> bool:
    s = normalize_for_regex(raw)
    return sum(1 for rx in REGEXES if rx.search(s)) >= 2


async def is_similar_banned(db, norm: str, threshold: float = 0.68) -> bool:
    await db.execute(text("SET pg_trgm.similarity_threshold = :t"), {"t": threshold})
    row = (await db.execute(
        text("""SELECT id FROM ban_messages
                WHERE normalized_text % :norm
                ORDER BY similarity(normalized_text, :norm) DESC
                LIMIT 1"""),
        {"norm": norm}
    )).first()
    return row is not None


def simhash64(norm: str) -> int:
    from collections import Counter
    v = [0]*64
    shingles = [norm[i:i+3] for i in range(max(1,len(norm)-2))]
    for sh, w in Counter(shingles).items():
        h = hashlib.md5(sh.encode()).digest()  # Ğ¾Ğº, Ñ‚ÑƒÑ‚ md5 ĞºĞ°Ğº Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ±Ğ¸Ñ‚
        x = int.from_bytes(h[:8], "big")
        for i in range(64):
            v[i] += w if (x >> i) & 1 else -w
    out = 0
    for i in range(64):
        if v[i] > 0: out |= (1 << i)
    return out

def hamming(a: int, b: int) -> int:
    return (a ^ b).bit_count()


def markers_in_text(norm: str) -> list[str]:
    """ĞšĞ°ĞºĞ¸Ğµ Ğ¼Ğ°Ñ€ĞºĞµÑ€Ñ‹ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ²ÑÑ‚Ñ€ĞµÑ‚Ğ¸Ğ»Ğ¸ÑÑŒ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ (Ğ¿Ğ¾ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸)."""
    return [k for k in SPAM_MARKERS if k in norm]

def regex_hits_list(raw: str) -> list[str]:
    """ĞšĞ°ĞºĞ¸Ğµ Ñ€ĞµĞ³ÑĞºÑĞ¿Ñ‹ ÑÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ (Ğ¿Ğ¾ Â«Ğ½Ğ¸Ğ¶Ğ½ĞµĞ¼Ñƒ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ñƒ + Ğ¿Ñ€Ğ¾Ğ±ĞµĞ»Ğ°Ğ¼Â» Ğ²ĞµÑ€ÑĞ¸Ğ¸)."""
    s = normalize_for_regex(raw)
    return [rx.pattern for rx in REGEXES if rx.search(s)]

@groups_monitor_router.message(F.chat.id == public_channel_comment_chat_id())
@async_connect_db(commit=False)
async def monitor_comments_for_ban(message: Message, bot: Bot, *, db: AsyncSession):
    user = message.from_user
    src_text = (message.text or message.caption or "").strip()

    # 0) Ğ”Ğ¾ÑÑ‚Ğ°Ñ‘Ğ¼ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ñ/ÑÑÑ‹Ğ»ĞºĞ¸ Ğ½Ğ° Ğ±Ğ¾Ñ‚Ğ¾Ğ²
    usernames = _extract_usernames(src_text)
    foreign_bots = {u for u in usernames if _is_foreign_bot(u)}
    has_foreign_bot = bool(foreign_bots)

    # 1) Ğ¢Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ¾ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸/Ñ…ÑÑˆÑƒ
    norm = normalize_message_text(src_text)
    is_banned_text = False
    if norm:
        h = norm_hash(norm)
        res = await db.execute(
            select(BanMessageText.id).where(BanMessageText.normalized_hash == h).limit(1)
        )
        is_banned_text = res.scalar_one_or_none() is not None

    # 2) ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ° (Ğ¼Ğ°Ñ€ĞºĞµÑ€Ñ‹/Ñ€ĞµĞ³ÑĞºÑĞ¿Ñ‹)
    markers = markers_in_text(norm) if norm else []
    rx_hits = regex_hits_list(src_text) if src_text else []
    rules_flag = (len(markers) >= 3) or (len(rx_hits) >= 2)

    # 3) ĞŸĞ¾Ñ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ (pg_trgm) â€” Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ½Ğµ ÑÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸ Ğ¿ÑƒĞ½ĞºÑ‚Ñ‹ (1) Ğ¸ (2),
    #    Ğ¸ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ (Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ Â«ÑÑ‚Ñ€ĞµĞ»ÑĞ»Ğ¾Â» Ğ½Ğ° ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… Ñ„Ñ€Ğ°Ğ·Ğ°Ñ…)
    similar_hit = False
    trigram_threshold = 0.66
    if norm and not is_banned_text and not rules_flag and len(norm) >= 60:
        similar_hit = await is_similar_banned(db, norm, threshold=trigram_threshold)

    # Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ
    should_ban = has_foreign_bot or is_banned_text or rules_flag or similar_hit

    if not should_ban:
        return  # Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ´ĞµĞ»Ğ°ĞµĞ¼

    # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ ÑƒĞ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ·Ğ°Ğ±Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¸ Ğ² ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ…, Ğ¸ Ğ² ĞºĞ°Ğ½Ğ°Ğ»Ğµ
    try:
        await message.delete()
    except TelegramBadRequest:
        pass

    try:
        await bot.ban_chat_member(chat_id=public_channel_comment_chat_id(), user_id=user.id)
    except TelegramBadRequest:
        pass
    try:
        await bot.ban_chat_member(chat_id=public_channel_chat_id(), user_id=user.id)
    except TelegramBadRequest:
        pass

    # Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ğ¼Ğ¾Ğµ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ (Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ Ğ·Ğ°Ğ±Ğ°Ğ½Ğ¸Ğ»Ğ¸)
    when = datetime.now(timezone.utc).astimezone().strftime("%Y-%m-%d %H:%M")
    reason_lines = []
    if foreign_bots:
        reason_lines.append(
            "ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°: ÑÑÑ‹Ğ»ĞºĞ°/ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ğµ Ğ±Ğ¾Ñ‚Ğ°(Ğ¾Ğ²): " + ", ".join(f"@{u}" for u in sorted(foreign_bots))
        )
    if is_banned_text:
        reason_lines.append("ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°: Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ Ñ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ñ‘Ğ½Ğ½Ğ¾Ğ¹ Ñ„Ñ€Ğ°Ğ·Ğ¾Ğ¹ (normalized_hash).")
    if rules_flag:
        reason_lines.append(
            f"ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°: Ğ¼Ğ°Ñ€ĞºĞµÑ€Ñ‹/Ñ€ĞµĞ³ÑĞºÑĞ¿Ñ‹ (Ğ¼Ğ°Ñ€ĞºĞµÑ€Ğ¾Ğ²: {len(markers)}, Ñ€ĞµĞ³ÑĞºÑĞ¿Ğ¾Ğ²: {len(rx_hits)})."
        )
        if markers:
            # ĞŸĞ¾ĞºĞ°Ğ¶ĞµĞ¼ Ğ´Ğ¾ 6 Ğ¼Ğ°Ñ€ĞºĞµÑ€Ğ¾Ğ², Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ Ñ€Ğ°Ğ·Ğ´ÑƒĞ²Ğ°Ñ‚ÑŒ ÑƒĞ²ĞµĞ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ
            reason_lines.append("ĞœĞ°Ñ€ĞºĞµÑ€Ñ‹: " + ", ".join(sorted(markers)[:6]) + ("â€¦" if len(markers) > 6 else ""))
        if rx_hits:
            # ĞŸĞ¾ĞºĞ°Ğ¶ĞµĞ¼ Ğ´Ğ¾ 3 Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²
            reason_lines.append("Regex: " + " | ".join(rx_hits[:3]) + ("â€¦" if len(rx_hits) > 3 else ""))
    if similar_hit:
        reason_lines.append(f"ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ°: Ğ¿Ğ¾Ñ…Ğ¾Ğ¶ĞµÑÑ‚ÑŒ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ¹ (pg_trgm â‰¥ {trigram_threshold}).")

    safe_text = html.escape(src_text) or "â€”"
    full_name = html.escape(getattr(user, "full_name", "") or "â€”")
    username = ("@" + user.username) if getattr(user, "username", None) else "â€”"
    lang = getattr(user, "language_code", None) or "â€”"
    is_premium = "Ğ´Ğ°" if getattr(user, "is_premium", False) else "Ğ½ĞµÑ‚"

    notify = (
        "<b>ğŸš¨ Ğ‘Ğ°Ğ½ Ğ² ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ÑÑ…</b>\n"
        f"<b>ĞšĞ¾Ğ³Ğ´Ğ°:</b> {when}\n"
        f"<b>ĞšÑ‚Ğ¾:</b> {full_name}\n"
        f"<b>Username:</b> {html.escape(username)}\n"
        f"<b>ID:</b> <code>{user.id}</code>\n"
        f"<b>Premium:</b> {is_premium}\n"
        f"<b>Ğ¯Ğ·Ñ‹Ğº:</b> {lang}\n"
        f"<b>Ğ¢ĞµĞºÑÑ‚:</b>\n<pre>{safe_text}</pre>\n"
        + ("\n".join(reason_lines) if reason_lines else "")
    )
    await bot.send_message(chat_id=elya_chat_id(), text=notify, parse_mode="HTML")