# services/cache/product_cache.py
from typing import Any

from redis.asyncio import Redis

from app.core.config import get_redis_settings

DEFAULT_EXPIRE_SECONDS = 300

redis = Redis(
    host=get_redis_settings().REDIS_HOST,
    port=get_redis_settings().REDIS_PORT,
    db=get_redis_settings().REDIS_CATALOG_INDEX,
    decode_responses=True,
)


def _make_key(prefix: str, user_id: int, obj_id: str) -> str:
    return f"{prefix}:{user_id}:{obj_id}"


def serialize_for_cache(data: Any) -> dict | list[dict]:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç Pydantic –º–æ–¥–µ–ª—å –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –≤ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Å–ª–æ–≤–∞—Ä—å/—Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç mode="json" –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ UUID, datetime –∏ –ø—Ä–æ—á–µ–≥–æ.
    """
    return
    # if isinstance(data, BaseModel):
    #     return data.model_dump(mode="json")
    # elif isinstance(data, list):
    #     return [item.model_dump(mode="json") if isinstance(item, BaseModel) else item for item in data]
    # elif isinstance(data, dict):
    #     return data
    # raise TypeError("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç –¥–ª—è –∫—ç—à–∞")


async def get_cached(prefix: str, user_id: int, obj_id: str):
    return None
    # key = _make_key(prefix, user_id, obj_id)
    # data = await redis.get(key)
    # if data:
    #     logger.info(f"~~~‚úÖ –ö–≠–® –ù–ê–ô–î–ï–ù | type={prefix} | user_id={user_id} | obj_id={obj_id} | key={key}~~~")
    #     return json.loads(data)
    # logger.info(f"~~~üö´ –ö–≠–® –ù–ï –ù–ê–ô–î–ï–ù | type={prefix} | user_id={user_id} | obj_id={obj_id} | key={key}~~~")
    # return None


async def set_cached(
    prefix: str,
    user_id: int,
    obj_id: str,
    data: dict,
    expire: int = DEFAULT_EXPIRE_SECONDS,
):
    return
    # key = _make_key(prefix, user_id, obj_id)
    # await redis.set(key, json.dumps(data), ex=expire)
    # logger.info(f"~~~üì¶ –ö–≠–® –°–û–•–†–ê–ù–Å–ù | type={prefix} | user_id={user_id} | obj_id={obj_id} | key={key} | TTL={expire}s~~~")


async def invalidate_cache(prefix: str, user_id: int, obj_id: str):
    return
    # key = _make_key(prefix, user_id, obj_id)
    # deleted = await redis.delete(key)
    # if deleted:
    #     logger.info(f"~~~‚ùå –ö–≠–® –£–î–ê–õ–Å–ù | type={prefix} | user_id={user_id} | obj_id={obj_id} | key={key}~~~")
    # else:
    #     logger.info(f"~~~‚ö†Ô∏è –ö–≠–® –ù–ï –ù–ê–ô–î–ï–ù –î–õ–Ø –£–î–ê–õ–ï–ù–ò–Ø | type={prefix} | user_id={user_id} | obj_id={obj_id} | key={key}~~~")


async def invalidate_all_by_prefix(prefix: str, user_id: int) -> int:
    return 0
    # pattern = f"{prefix}:{user_id}:*"
    # keys = await redis.keys(pattern)
    # if keys:
    #     await redis.delete(*keys)
    #     logger.info(f"~~~‚ùåüßπ –£–î–ê–õ–ï–ù–û –í–°–ï –ö–≠–®–ò –ü–û –®–ê–ë–õ–û–ù–£ | prefix={prefix} | user_id={user_id} | count={len(keys)} | pattern={pattern}~~~")
    #     return len(keys)
    # else:
    #     logger.info(f"~~~‚ÑπÔ∏è –ù–ï–¢ –ö–≠–®–ê –î–õ–Ø –£–î–ê–õ–ï–ù–ò–Ø | prefix={prefix} | user_id={user_id} | pattern={pattern}~~~")
    #     return 0
